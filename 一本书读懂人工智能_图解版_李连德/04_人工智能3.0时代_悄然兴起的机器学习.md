人工智能(Artificial Intelligence)

4.3 有监督学习和无监督学习
---

监督学习
---

所谓有监督学习，就是我们通常说的分类，也就是通过已有的信息获得一个最优的处理模式，再利用这个模式将所有输入的信息处理成输出信息，计算机通过对输出信息进行简单的判断将已有信息分成不同种类，这样人工智能就有了对未知数据的分类能力，比如：家长教育孩子香蕉可以吃石头不能吃，“香蕉”，“石头”就是输入信息，而家长下的判断“能吃”，“不能吃”就是相应的输出信息，当孩子认识达到一定水平时，会逐步形成一种通用或泛化的模式，这种模式是通过有监督学习训练出来的，当孩子遇到与石头相同事物时就知道不能吃的，临近算法就是理论比较成熟的有监督学习的应用。

临近算法是最简单的机器学习算法之一，其总体思路如下;如果一个样本在特定空间内有K个类似的样本，并且这些样本大多数属于同一类别，那么这个样本技术属于这个类别，

由于临近算法主要靠周围有限的邻近样本来判断目标样本所属的类别，因此在判断之前要确认所选择的临近样本都是正确的分类对象，这就是所谓的“监督”

无监督学习
---

那么什么是无监督学习呢？在研究者眼中，无监督学习更具有探索价值。它与有监督学习不同之处在于，在机器学习的时候，我们并没有放置任何可供参考的样本或已分类的参考目标，机器需要直接对已有的数据建立模型，我们不禁会问，没有样本的话，计算机怎么自己建立模型？在人类运用思维过程中，无监督学习时常会发生，比如：音乐我们听不懂，但是能听出那些比较欢快那些比较低沉，我们能自发的对音乐进行分类，这就是无监督学习，并没有人给我们模型将听到的音乐进行分类，这就是无监督学习。我们根据事物特征将其归为一类的时候，使用的就是无监督学习中的聚类分析法

聚类分析法是无监督学习的典型案例。俗话说“物以类聚，人以群分”，所谓的类就是具有相似元素的事物的集合。

聚类分析的目的是在相似的基础上收集数据进行分类，很多领域都会使用到聚类分析，包括计算机科学，统计学，生物学和数学等，聚类分析的对象被成为描述数据，通过衡量它们和不同数据源之间的相似性，就能把不同数据源归到不同的类别。比如我们找到了一棵植物，并且发现它有白菜的属性，只是颜色不一样，那么我们就可以将其归类到蔬菜中。

从实际应用的角度来看，聚类分析是数据挖掘的主要任务之一，聚类能够作为一个独立的工具获得数据的分布情况，观察每一簇数据的特征，集中对特定聚簇集合进行分析，另外，聚类分析还可作为其它算法(如分类和定性归纳算法)的预处理步骤。

当有足够的数据支撑时，无监督学习中的聚合能力会无限放大，特别是当一个聚类分析中的目标具有附加数据时，这些附加数据能不断构建出一个又一个新模型，所以产生的结果会几何级增大。

当然并不是有了无监督学习，有监督学习就完全没有存在的意义，恰当的使用分类系统，机器学习也会变得非常强大，在一定程度上，机器学习这种分类可以打破语义难以理解的障碍，通过不断的将有监督学习和无监督学习相融合，语义也可以变成可分类的目标之一，如果没有这种方法促进机器学习，那么语义的理解变成一件非常困难的事情。

4.4 各种分类方法
---

根据基础理论不同，临近算法只是其中一种，与临近算法相似的经典算法还有四种，1 决策树 2正则化法 3朴素贝叶斯算法 4人工神经网络。

1 决策树
---

决策树是通过设定一定的范围区间，通过目标物属性是否符合范围区间的值进行分类，比如：“国家”和“政党”通常出现在政治领域中，如果出现某个目标物，可以将数据区分为含有“国家”这个词的集合和不含这个词的集合，含“政党”这个词的集合和不含这个词的集合；如果目标物既含有“国家”同时也含有“政党”，那么自然会被归类到“政治”这个维度，决策树通过不断的生成问题逐步缩小范围，最终通过询问是否含有某一个关键词就知道目标物的大致属于的类别。

一般来说企业倾向于使用分类的方法，通过已录用员工的特点进行整合，生成决策树以后，就能筛选出适合的面试者，但是，这种分类方法一旦遇到多属性的复合条件，就容易发生多重分类，因此精度不高。

2 正则化法
---

正则化法可以看做是决策树或其它算法的延展算法，它根据算法的复杂度对现有的算法进行优化，调整，也就是反问题化。一般说来，正则化法是是对其它算法建立的简单模型进行奖励，对复杂模型进行惩罚。

3、朴素贝叶斯算法
---

与决策树划定区间的方法截然不同，朴素贝叶斯算法有关概率的最终分类方法。它可以将数据的每种特征可能被划入的类别概率加总，最终根据加总结果判断数据应属的类别。比如，在“政治”里，“国家”出现的概率是1/10，在“数学”里，国家出现的概率是1/30，那么“国家”纳入“政治”的概率比较高。

4、人工神经网络
---

相对于决策树和朴素贝叶斯算法，人工神经网络是一种更加“高大上”的算法，从技术角度来说，人工神经网络更像是真正意义上的人工智能的计算方式，因为它是通过模仿人类脑神经回路进行分类的。

人的大脑通过神经元传输信息，数据量巨大的神经元构成了神经网络，当某一个神经元接收到信号刺激后，就会传输给另一个神经元，这样逐层传递给大脑进行处理后就形成了感知，就好比传感器，当刺激达到某一个值的时候，传感器会形成反应，如果没有达到某个值不会形成感应。

人工神经网络就是仿照神经元信息传递方法对数据进行分类，可以在传递过程中设置权重，如果数值小于这个权重那么就不能传递到下一个“神经元”中，反之，如果数据大于这个权重，则继续往下传递，在这样的不断传递过程中，数据就会被分类到各个维度中。

4.5 用人工神经网络识别手写字
---

人工神经网络是人脑神经元的抽象描述，它从信息处理的角度来建立简单模型，按照不同的连接方式组成各种各样的“神经网络”，不过，人工神经网络并不是真的由神经元组成，这种神经网络由大量的节点相互连接而成，每个节点都可以看做一个独立的输出系统，而两个节点之间能够进行数据传输的框架被称为权重，当信息在节点之间传递的时候，根据权重值的不同，信息经过的节点也会有所不同，最终整个神经网络会在不断筛选和传输过程中逐步逼近自然界中存在的某种算法或者逻辑思维，从而实现语言转换，完成机器学习。

值得一体的是，人工神经网络的一大优势就是权重可以根据需要进行调整，每两个神经元直接都存在4中“权重通道”，通过调节“权重通道”的宽度，不同的数据分类的精度就可以达到一个让人满意的程度，举个简单的例子：如果我们有100个节点，那么经过计算，能够构造出“权重通道”就有8万条，也就是说100个节点可以筛选8万条信息。如果节点数量达到千万或者上亿级别，就可以分类海量数据。

一旦输出结果是错误的，我们就需要调整权重就能提高分类的精度，相对于其它方法，人工神经网络是从答案入手来调整过程中出现的偏差的，而不是从头重新来过，寻找一条新的通道来得出最后的答案。就好像企业发展出现偏差时，我们需要寻找领导层、决策层失误，而不是寻找基层员工，只有这样才能适时做出调整，对于手写文字这个问题，人工神经网络在语言或语种出现的时候，能够以最快的速度重新进行分类，对于整个人工智能领域来说，人工神经网络把很多不可能的事变成了可能，在一定程度上决定了人工智能真正走上了“类人”的发展轨道。

4.6 机器学习的难点
---

机器学习这个概念在产生的时候，本身就有一个明显的弱点，只不过这个弱点一直得不到重视，随着人们在机器学习领域成果越来越多，这一缺点才充分暴露出来---特征工程

我们从小认东西的时候，基本上就是通过一个又一个特征来记住某一个或某一类事物，比如，我们没有脚、爬行这两个特征记住蛇，没有脚、爬行就是蛇的特征。

通过特征人们可以辨别以前没有见过的东西，对于成年人，来说记住这些特征是一件很容易的事情，但是如何让计算机记住特征呢？它没有各种感觉，要让它记住特征就教授它一些有用的特征量，那么对于一件事物，我们应该选择怎样的特征量让计算机记住呢？

如果让计算机记住豹子，需要让它记住“有斑点”、“猫科动物”这个特征量，当计算机遇到斑点狗的时候，就会错误的认为这是豹子。

从这一点来看，选取什么样的特征量决定了运算过程的精度，就像手写文件系统，为什么10个数字的图片要准备7万张，原因就在于这里。

继自然语言处理之后，如何让计算机选择合适的特征量就成为人工智能发展需要客服的又一道难题。如果无法突破自我选取特征量的难点，人工智能可能永远是人类一个美梦。
